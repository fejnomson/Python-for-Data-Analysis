# NumPy ndarray
import numpy as np
data = np.array([
	[0.9526, -0.246, -0.8856],
	[0.5639, 0.2379, 0.9104]
])
data * 10
data.dtype
data.shape

# Creating ndarrays
data1 = [6, 7.5, 8, 0, 1]
arr1 = np.array(data1)
data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]
arr2 = np.array(data2)
arr2.ndim
arr2.shape
arr1.dtype
arr2.dtype
np.zeros(10)
np.zeros((3, 6))
np.empty((2, 3, 2)) # not literally empty
np.arange(15) # range()

# Data Types for ndarrays
# dtype is an OBJECT that has info that ndarray needs
arr1 = np.array([1, 2, 3], dtype = np.float64)
arr2 = np.array([1, 2, 3], dtype = np.int32)
arr1.dtype
arr2.dtype
arr = np.array([1, 2, 3, 4, 5])
arr.dtype
float_arr = arr.astype(np.float64)
float_arr.dtype
# float to int will truncate, not round!!
numeric_strings = np.array(['1.25', '-9.6', '42'], dtype = np.string_)
numeric_strings.astype(float)
int_array = np.arange(10)
calibers = np.array([.22, .27, .357, .38, .44, .5])
int_array.astype(calibers.dtype)
empty_uint32 = np.empty(8, dtype = 'u4') # shorthand
empty_uint32

# Operations between Arrays and Scalars
arr = np.arange(10)
arr_slice = arr[5:8]
arr_slice[1] = 12345
arr # changing arr_slice changes arr! arr_slice is a view of arr, not a
# 	copy, so it just REFERS to arr. super different than r. This is to avoid
# 	performance and memory problems.
arr_slice2 = arr[5:8].copy()
arr_slice2[1] = 9999
arr_slice2
arr
# use .copy() to make r-like copy; wont modify original; doesn't return a view
arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
arr2d[2]
arr2d[0][2]
arr2d[0, 2]
arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])
arr3d
arr3d[0]
old_values = arr3d[0].copy()
arr3d[0] = 42
arr3d[0] = old_values
arr3d[1, 0]

# Boolean Indexing
names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])
data = np.random.randn(7, 4)
data[names == 'Bob']
data[names == 'Bob', 2:]
names != 'Bob'
data[-(names == 'Bob')]
mask = (names == 'Bob') | (names == 'Will')
data[mask]
# BOOLEAN INDEXING ALWAYS CREATES A COPY OF THE DATA!!!!!
data[data < 0] = 0
data[names != 'Joe'] = 7

# Fancy Indexing
# 	Fancy indexing always makes copy, similar to boolean indexing
arr = np.empty((8, 4))
for i in range(8):
	arr[i] = i
arr
arr[[4, 3, 0, 6]]
arr[[-3, -5, -7]]
arr = np.arange(32).reshape((8, 4))
arr
arr[[1, 5, 7, 2], [0, 3, 1, 2]]
arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]]
arr[np.ix_([1, 5, 7, 2], [0, 3, 1, 2])]

# Transposing Arrays and Swapping Axes
arr = np.arange(15).reshape((3, 5))
arr
arr.T # has attribute storing transposed version
arr = np.random.randn(6, 3)
np.dot(arr.T, arr)
# transpose will return a view
arr = np.arange(16).reshape((2, 2, 4))
arr
arr.transpose((1, 0, 2))
arr.swapaxes(1, 2) # returns view

# Universal Functions: Fast Element-wise Array Functions

# Data Processing Using Arrays
points = np.arange(-5, 5, 0.01)
xs, ys = np.meshgrid(points, points)

# Expressing Conditional Logic as Array Operations
xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])
yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])
cond = np.array([True, False, True, True, False])
result = np.where(cond, xarr, yarr) # ifelse()
arr = np.random.randn(4, 4)
arr
np.where(arr > 0, 2, -2) # works on multidim arrays also

# Mathematical and Statistical Methods
arr = np.random.randn(5, 4)
arr.mean() # instance method
np.mean(arr) # top level numpy function
arr.sum()
arr.mean(axis = 1)
arr.mean(axis = 0) # note that these aggregate, reductions
arr = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
arr.cumsum(0)
arr.cumprod(0)

# Methods for Boolean Arrays
# bools coerced into 1 and 0
arr = np.random.randn(100)
(arr > 0).sum()
bools = np.array([False, False, True, False])
bools.any() # what it should be
bools.all()

# Sorting
from numpy.random import randn
arr = randn(8)
arr.sort() # in place, not copy on modify
arr = randn(5, 3)
arr
x = arr.copy()
x.sort(1) # sorts each 'row'
x
y = arr.copy()
y.sort(0) # sorts each 'column'
y
np.sort(arr) # top leve l RETURNS COPY INSTEAD OF MOD IN PLACE

# Unique and Other Set Logic
np.unique(names)
names.unique() # no instance method
sorted(set(names)) # pure python
values = np.array([6, 0, 0, 3, 2, 5, 6])
np.in1d(values, [2, 3, 6]) # %in%
values[np.in1d(values, [2, 3, 6])]
# array set ops: these look fine 
x = pd.Series(['a', 'b', 'c', 'd'])
np.in1d(x, ['b']) # looks like this works fine for series

# File Input and Output with Arrays
# read and write arrays to disk
# np.save and np.load
arr = np.arange(10)
np.save('some_array', arr)
np.load('some_array.npy')
np.savez('array_archive.npz', a = arr, b = arr) # 'zip archive'
arch = np.load('array_archive.npz')
arch['b']
arch['a'] # loads in dict like object

# Saving and Loading Text Files
# don't think this matters... would just save as csv or text using pandas api

# Linear Algebra
# Don't need this right now?

# Random Number Generation
# numpy.random module
# Don't need this right now? Just know use this instead of base python

# Example: Random Walks
nsteps = 1000
draws = np.random.randint(0, 2, size = nsteps)
steps = np.where(draws > 0, 1, -1)
walk = steps.cumsum()
walk.min()
walk.max()
(np.abs(walk) >= 10).argmax() # (boolean for if over 10 away from origin).firstoccurance

# Simulating Many Random Walks at Once
nwalks = 5000
nsteps = 1000
draws = np.random.randint(0, 2, size = (nwalks, nsteps)) # 0 or 1
# so size arg takes tuple indicating how many sub-arrays of random
# 	numbers you want
steps = np.where(draws > 0, 1, -1)
# as expected
walks = steps.cumsum(1)
# take cumsum for each sub-array
walks
walks.max()
walks.min()
hits30 = (np.abs(walks) >= 30).any(1) # any don't cross 30? accross 'rows'
hits30
hits30.sum()
crossing_times = (np.abs(walks[hits30]) >= 30).argmax(1)
# of the 'rows' that hit 30 or -30, which ones were 30 or -30, find first
# 	occurance using argmax (rowwise)
crossing_times.mean()
# so on average, it takes 500 coin flips to get 30 away from origin
